{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Memory-Enhanced Conversational Agent\n",
    "\n",
    "## Overview\n",
    "This tutorial outlines the process of creating a conversational AI agent with enhanced memory capabilities. The agent incorporates both short-term and long-term memory to maintain context and improve the quality of interactions over time.\n",
    "\n",
    "## Motivation\n",
    "Traditional chatbots often struggle with maintaining context beyond immediate interactions. This limitation can lead to disjointed conversations and a lack of personalization. By implementing both short-term and long-term memory, we aim to create an agent that can:\n",
    "- Maintain context within a single conversation\n",
    "- Remember important information across multiple sessions\n",
    "- Provide more coherent and personalized responses\n",
    "\n",
    "## Key Components\n",
    "1. **Language Model**: The core AI component for understanding and generating responses.\n",
    "2. **Short-term Memory**: Stores the immediate conversation history.\n",
    "3. **Long-term Memory**: Retains important information across multiple conversations.\n",
    "4. **Memory Manager**: Handles the storage and retrieval of information in both memory types.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Setting Up the Environment\n",
    "1. Import necessary libraries for the language model, memory management, and prompt handling.\n",
    "2. Initialize the language model with desired parameters (e.g., model type, token limit).\n",
    "\n",
    "### Implementing Memory Systems\n",
    "1. Create a store for short-term memory (conversation history):\n",
    "   - Use a dictionary to manage multiple conversation sessions.\n",
    "   - Implement a function to retrieve or create new conversation histories.\n",
    "\n",
    "2. Develop a long-term memory system:\n",
    "   - Create a separate store for persistent information.\n",
    "   - Implement functions to update and retrieve long-term memories.\n",
    "   - Define simple criteria for what information to store long-term (e.g., longer user inputs).\n",
    "\n",
    "### Building the Conversational Logic\n",
    "1. Combine the prompt template with the language model.\n",
    "2. Wrap this combination with a component that manages message history.\n",
    "3. Ensure the chain can access and update both short-term and long-term memory.\n",
    "\n",
    "### Creating the Interaction Loop\n",
    "1. Develop a main chat function that:\n",
    "   - Retrieves relevant long-term memories.\n",
    "   - Invokes the conversational chain with the current input and memories.\n",
    "   - Updates the long-term memory based on the interaction.\n",
    "   - Returns the AI's response.\n",
    "\n",
    "### Testing and Refinement\n",
    "1. Run example conversations to test the agent's ability to maintain context.\n",
    "2. Review both short-term and long-term memories after interactions.\n",
    "3. Adjust memory management criteria and prompt structure as needed.\n",
    "\n",
    "## Conclusion\n",
    "The Memory-Enhanced Conversational Agent offers several advantages over traditional chatbots:\n",
    "\n",
    "- **Improved Context Awareness**: By utilizing both short-term and long-term memory, the agent can maintain context within and across conversations.\n",
    "- **Personalization**: Long-term memory allows the agent to remember user preferences and past interactions, enabling more personalized responses.\n",
    "- **Flexible Memory Management**: The implementation allows for easy adjustment of what information is stored long-term and how it's used in conversations.\n",
    "- **Scalability**: The session-based approach allows for managing multiple independent conversations.\n",
    "\n",
    "This implementation provides a foundation for creating more sophisticated AI agents. Future enhancements could include:\n",
    "- More advanced criteria for long-term memory storage\n",
    "- Implementation of memory consolidation or summarization techniques\n",
    "- Integration with external knowledge bases\n",
    "- Emotional or sentiment tracking across interactions\n",
    "\n",
    "By focusing on memory enhancement, this conversational agent design significantly improves upon basic chatbot functionality, paving the way for more engaging, context-aware, and intelligent AI assistants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, we'll import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_base_url = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Initialize the language model\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Stores\n",
    "\n",
    "We'll create stores for both short-term (chat history) and long-term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store = {}  # Store short-term chat history for each session\n",
    "long_term_memory = {}  # Store long-term memory for each session\n",
    "# e.g. long_term_memory = {\"session_id\": [{\"role\": \"user\", \"content\": \"Hello\"}, {\"role\": \"assistant\", \"content\": \"Hi there!\"}]}\"}\n",
    "\n",
    "# Function to get chat history\n",
    "def get_chat_history(session_id: str):\n",
    "    if session_id not in chat_store:\n",
    "        chat_store[session_id] = []\n",
    "    return chat_store[session_id]\n",
    "\n",
    "# Function to update long-term memory\n",
    "def update_long_term_memory(session_id: str, input_text: str, output_text: str):\n",
    "    if session_id not in long_term_memory:\n",
    "        long_term_memory[session_id] = []\n",
    "    \n",
    "    if len(input_text) > 20:\n",
    "        message = [\n",
    "            {\"role\": \"user\", \"content\": input_text},\n",
    "            {\"role\": \"assistant\", \"content\": output_text}\n",
    "        ]\n",
    "        long_term_memory[session_id].append(message)\n",
    "    \n",
    "    if len(long_term_memory[session_id]) > 5:\n",
    "        long_term_memory[session_id] = long_term_memory[session_id][-5:]\n",
    "\n",
    "# Function to get long-term memory\n",
    "def get_long_term_memory(session_id: str):\n",
    "    return \". \".join(str(item) for item in long_term_memory.get(session_id, []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation\n",
    "\n",
    "To generate responses, we manually build the prompt and call the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str, session_id: str):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model ,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,  # Controls randomness\n",
    "        max_tokens=150  # Limits the number of tokens in the response\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Logic\n",
    "\n",
    "This is the core of the conversation flow, where we combine short-term and long-term memories and generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input_text: str, session_id: str):\n",
    "    long_term_mem = get_long_term_memory(session_id)\n",
    "    chat_history = get_chat_history(session_id)\n",
    "    \n",
    "    # Build the prompt, including both long-term memory and chat history\n",
    "    prompt = f\"You are a helpful AI assistant. Use the information from long-term memory if relevant.\\n\"\n",
    "    prompt += f\"Long-term memory: {long_term_mem}\\n\" if long_term_mem else \"No long-term memory yet.\\n\"\n",
    "    \n",
    "    # Add chat history to the prompt\n",
    "    for message in chat_history:\n",
    "        prompt += f\"{message['role']}: {message['content']}\\n\"\n",
    "    \n",
    "    # Add the current user input to the prompt\n",
    "    prompt += f\"user: {input_text}\\n\"\n",
    "    \n",
    "    # Get the response based on the built prompt\n",
    "    response = generate_response(prompt, session_id)\n",
    "    \n",
    "    # Add the user input and AI response to the chat history\n",
    "    chat_history.append({\"role\": \"user\", \"content\": input_text})\n",
    "    chat_history.append({\"role\": \"assitant\", \"content\": response})\n",
    "    \n",
    "    # Update long-term memory\n",
    "    update_long_term_memory(session_id, input_text, response)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Let's test our memory-enhanced conversational agent with a series of interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello, Alice! How can I assist you today?\n",
      "AI: I'm sorry, but I don't have real-time weather data. However, you can check a weather website or app for the most accurate and current information. Is there anything else I can help you with?\n",
      "AI: That's great to hear, Alice! Sunny days can be so uplifting and enjoyable. Do you have any favorite activities you like to do on sunny days?\n",
      "AI: Yes, Alice! I remember your name. How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_123\"\n",
    "\n",
    "print(\"AI:\", chat(\"Hello! My name is Alice.\", session_id))\n",
    "print(\"AI:\", chat(\"What's the weather like today?\", session_id))\n",
    "print(\"AI:\", chat(\"I love sunny days.\", session_id))\n",
    "print(\"AI:\", chat(\"Do you remember my name?\", session_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Memory\n",
    "\n",
    "Let's review the conversation history and long-term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation History:\n",
      "user: Hello! My name is Alice.\n",
      "assitant: Hello, Alice! How can I assist you today?\n",
      "user: What's the weather like today?\n",
      "assitant: I'm sorry, but I don't have real-time weather data. However, you can check a weather website or app for the most accurate and current information. Is there anything else I can help you with?\n",
      "user: I love sunny days.\n",
      "assitant: That's great to hear, Alice! Sunny days can be so uplifting and enjoyable. Do you have any favorite activities you like to do on sunny days?\n",
      "user: Do you remember my name?\n",
      "assitant: Yes, Alice! I remember your name. How can I assist you further?\n",
      "\n",
      "Long-term Memory:\n",
      "[{'role': 'user', 'content': 'Hello! My name is Alice.'}, {'role': 'assistant', 'content': 'Hello, Alice! How can I assist you today?'}]. [{'role': 'user', 'content': \"What's the weather like today?\"}, {'role': 'assistant', 'content': \"I'm sorry, but I don't have real-time weather data. However, you can check a weather website or app for the most accurate and current information. Is there anything else I can help you with?\"}]. [{'role': 'user', 'content': 'Do you remember my name?'}, {'role': 'assistant', 'content': 'Yes, Alice! I remember your name. How can I assist you further?'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConversation History:\")\n",
    "for message in chat_store[session_id]:\n",
    "    print(f\"{message['role']}: {message['content']}\")\n",
    "\n",
    "print(\"\\nLong-term Memory:\")\n",
    "print(get_long_term_memory(session_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
